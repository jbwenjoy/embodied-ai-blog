---
layout: article
title: Diffusion
permalink: /diffusion/
---


# å…ˆçœ‹è§†é¢‘



ã€ç®€å•æ˜“æ‡‚Diffusionæ¨¡å‹ç»¼è¿° - åŸºç¡€ç®—æ³•è¯¦è§£ã€‘ https://www.bilibili.com/video/BV1TP4y1Q7qJ/?share_source=copy_web&vd_source=0261590b30f63d16142104bb154164d9

ã€Why Does Diffusion Work Better than Auto-Regression?(ä¸ºä»€ä¹ˆæ‰©æ•£æ¯”è‡ªå›å½’æ›´æœ‰æ•ˆï¼Ÿ)ã€‘ https://www.bilibili.com/video/BV1zb42187Ec/?share_source=copy_web&vd_source=0261590b30f63d16142104bb154164d9

ã€å¤§ç™½è¯01ä¸€æ–‡ç†æ¸… Diffusion Model æ‰©æ•£æ¨¡å‹ | åŸç†å›¾è§£+å…¬å¼æ¨å¯¼ã€‘ https://www.bilibili.com/video/BV1xih7ecEMb/?share_source=copy_web&vd_source=0261590b30f63d16142104bb154164d9



# diffusionæ˜¯ä»€ä¹ˆï¼Ÿ



## **âœ… Diffusion çš„ç›®æ ‡æ˜¯å­¦ä¹ å›¾åƒåˆ†å¸ƒ**

æˆ‘ä»¬æœ‰å¾ˆå¤šçœŸå®å›¾åƒæ ·æœ¬ $x_0 \sim p_{\text{data}}(x)$ï¼Œxè¡¨ç¤ºå›¾åƒï¼Œè¿™äº›å›¾åƒæœ¬èº«å¯èƒ½æ¥è‡ªå¾ˆå¤æ‚çš„åˆ†å¸ƒï¼Œæ¯”å¦‚ï¼š

- æœ‰çŒ«ã€æœ‰ç‹—ã€æœ‰æˆ¿å­
- æœ‰é¢œè‰²ã€æœ‰çº¹ç†ã€æœ‰è¾¹ç¼˜
- è¿™äº›å†…å®¹åœ¨å›¾åƒåƒç´ ç©ºé—´ä¸­æœ‰ **ç»Ÿè®¡ç›¸å…³æ€§**

## **ğŸ§  æ‰€ä»¥æˆ‘ä»¬æƒ³å­¦è¿™ä¸ªåˆ†å¸ƒ** $p_{\text{data}}(x)$

å­¦åˆ°äº†è¿™ä¸ªåˆ†å¸ƒå°±èƒ½è‡ªå·±ç”Ÿæˆçœ‹ä¸Šå»è¿˜ä¸é”™çš„å›¾ç‰‡äº†ã€‚

ä½†æ˜¯è¿™ä¸ªåˆ†å¸ƒæ˜¯æˆ‘ä»¬ä¸çŸ¥é“çš„ï¼Œç›´æ¥å»ºæ¨¡å®ƒå¤ªéš¾äº†ï¼Œäºæ˜¯ diffusion åšäº†ä¸€ä»¶ç‰¹åˆ«å·§å¦™çš„äº‹ï¼š



------



### **ğŸ§Š 1.** **æ„é€ ä¸€ä¸ªå®¹æ˜“çš„åˆ†å¸ƒï¼šé«˜æ–¯å™ªå£°**

æˆ‘ä»¬çŸ¥é“ä¸€ä¸ªå¾ˆç®€å•çš„åˆ†å¸ƒï¼šæ ‡å‡†æ­£æ€åˆ†å¸ƒ $\mathcal{N}(0, I)$ã€‚

å®ƒæ²¡æœ‰ä»»ä½•ç»“æ„â€”â€”çº¯å™ªå£°ã€‚

### **ğŸ” 2.** **ä¸€æ­¥æ­¥æŠŠçœŸå®å›¾åƒâ€œæ¯æ‰â€ï¼Œå˜æˆé«˜æ–¯**

è¿™ä¸ªè¿‡ç¨‹æ˜¯æˆ‘ä»¬è‡ªå·±è®¾è®¡å‡ºæ¥çš„ï¼Œå«åš **å‰å‘æ‰©æ•£è¿‡ç¨‹**ï¼ˆForward Diffusionï¼‰ï¼š

$x_0 \rightarrow x_1 \rightarrow \cdots \rightarrow x_T \approx \mathcal{N}(0, I)$

æ¯ä¸€æ­¥æˆ‘ä»¬äººä¸ºåŠ å™ªã€‚æœ€ç»ˆä½ ä¼šæŠŠç»“æ„ä¸°å¯Œçš„å›¾åƒå˜æˆç»“æ„å…¨æ— çš„å™ªå£°ã€‚

è¿™ä¸€æ­¥æ˜¯æœ‰ closed-form çš„ï¼ˆå¯ä»¥ç›´æ¥è®¡ç®—ï¼‰ï¼Œä¸éœ€è¦è®­ç»ƒã€‚

### **ğŸ§‘â€ğŸ“ 3.** **è®­ç»ƒä¸€ä¸ªç¥ç»ç½‘ç»œåšâ€œå»å™ªâ€**

è¿™æ—¶å€™æˆ‘ä»¬è¦è®­ç»ƒä¸€ä¸ªç¥ç»ç½‘ç»œæ¥â€œé€†è½¬â€è¿™ä¸ªè¿‡ç¨‹ï¼Œè®©å®ƒå­¦ä¼šï¼š

$x_T \rightarrow x_{T-1} \rightarrow \cdots \rightarrow x_0$

ä½†è¿™ä¸ªè¿‡ç¨‹æœ¬èº«ä¸æ˜¯æˆ‘ä»¬æœ‰ç°æˆæ•°æ®çš„ï¼Œè€Œæ˜¯æˆ‘ä»¬é€šè¿‡è®­ç»ƒè®©ç¥ç»ç½‘ç»œ**å­¦ä¼šå¦‚ä½•ä¸€æ­¥æ­¥è¿˜åŸç»“æ„**ã€‚

ä¸ºäº†è®­ç»ƒè¿™ä¸ªç½‘ç»œï¼Œå¤§å®¶è®¾è®¡äº†ä¸€ä¸ªå¾ˆå·§çš„ç›®æ ‡å‡½æ•°ï¼Œå°±æ˜¯è®©ç½‘ç»œé¢„æµ‹ä½ åŠ è¿›å»çš„å™ªå£° $\epsilon$ï¼Œä»è€Œé—´æ¥å­¦ä¼šè¿˜åŸå›¾åƒã€‚

### **ğŸ¤– æ‰€ä»¥ä½ è®­ç»ƒçš„ç¥ç»ç½‘ç»œå…¶å®åœ¨åšï¼š**

- ç»™å®ƒä¸€ä¸ª noisy å›¾åƒ $x_t$
- ç»™å®ƒä¸€ä¸ªæ—¶é—´æ­¥ $t$
- å®ƒè¦é¢„æµ‹çš„æ˜¯è¿™ä¸ªå›¾åƒä¸­æœ‰å¤šå°‘å™ªå£°ï¼ˆä¹Ÿå°±æ˜¯ä½ åŠ äº†å¤šå°‘æ‰°åŠ¨ï¼‰
- è¿™æ ·ä½ å°±èƒ½ä¸€æ­¥æ­¥â€œåç€èµ°â€å›å»ï¼Œè¿˜åŸå‡ºåŸå§‹å›¾åƒ

## **âœ… æœ€ç»ˆç›®æ ‡ï¼šç”Ÿæˆå›¾åƒï¼**

ä¸€æ—¦ä½ è®­ç»ƒå¥½äº†è¿™ä¸ªâ€œå»å™ªç¥ç»ç½‘ç»œâ€ï¼Œä½ å°±å¯ä»¥ï¼š

1. ä» $x_T \sim \mathcal{N}(0, I)$ é‡‡ä¸€ä¸ªéšæœºå™ªå£°
2. åå¤åº”ç”¨ç½‘ç»œï¼Œä¸€æ­¥æ­¥å»å™ª
3. æœ€ç»ˆä½ å¾—åˆ°ä¸€ä¸ªæ–°çš„ $x_0$ï¼Œå®ƒæ˜¯æ¥è‡ªäºå­¦åˆ°çš„å›¾åƒåˆ†å¸ƒ $p_{\text{data}}(x)$ã€‚è¿™å°±å®Œæˆäº†å›¾åƒç”Ÿæˆã€‚

## **ğŸ“Œ æ‰€ä»¥ diffusion çš„æ ¸å¿ƒç»“æ„æ˜¯ï¼š**

- è®¾è®¡ Forward è¿‡ç¨‹ï¼ˆäººä¸ºåŠ å™ªï¼Œæ¨¡æ‹Ÿéšæœºæ€§ï¼‰
- è®­ç»ƒç¥ç»ç½‘ç»œå­¦ä¼š Reverseï¼ˆä¸€æ­¥æ­¥å»å™ªï¼‰
- æ¨ç†çš„æ—¶å€™ä»é«˜æ–¯å™ªå£°å‡ºå‘ï¼Œç”¨ç¥ç»ç½‘ç»œâ€œç”Ÿæˆå›¾åƒâ€



------



# æ€ä¹ˆåšå‘¢ï¼Ÿ



## **ğŸ§  å›é¡¾ï¼šæˆ‘ä»¬çš„ç›®æ ‡æ˜¯å­¦ä¼šâ€œåå‘è¿˜åŸå›¾åƒâ€**

æˆ‘ä»¬è®¾è®¡äº†ä¸€ä¸ªå‰å‘è¿‡ç¨‹ï¼ŒæŠŠçœŸå®å›¾åƒä¸€æ­¥æ­¥åŠ å™ªï¼š

$q(x_t \mid x_{t-1}) = \mathcal{N}(x_t; \sqrt{1 - \beta_t} x_{t-1}, \beta_t I)$

æœ€ç»ˆåˆ°ç¬¬ T æ­¥å˜æˆçº¯é«˜æ–¯å™ªå£° $x_T \sim \mathcal{N}(0, I)$ã€‚

æˆ‘ä»¬è¦è®­ç»ƒçš„ç¥ç»ç½‘ç»œï¼Œæ˜¯å­¦ä¼šâ€œä» noisy å›¾åƒä¸­é€æ­¥å»å™ªâ€ï¼Œä¹Ÿå°±æ˜¯ä¼°è®¡ï¼š

$p_\theta(x_{t-1} \mid x_t)$



### **åŸºæœ¬å˜é‡å®šä¹‰ï¼š**

| **ç¬¦å·**                                | **å«ä¹‰**                                |
| --------------------------------------- | --------------------------------------- |
| $x_0$                                   | åŸå§‹å›¾åƒï¼ˆæ¥è‡ªè®­ç»ƒé›†ï¼‰                  |
| $x_t$                                   | ç¬¬ t æ­¥åŠ å™ªåçš„å›¾åƒï¼ˆåŒ…å«éƒ¨åˆ†å™ªå£°ï¼‰     |
| $T$                                     | æ€»å…±åŠ å™ªçš„æ­¥æ•°ï¼Œæ¯”å¦‚ 1000 æ­¥            |
| $\beta_t$                               | ç¬¬ t æ­¥åŠ è¿›å»çš„å™ªå£°å¼ºåº¦ï¼ˆå™ªå£°è°ƒèŠ‚å› å­ï¼‰ |
| $\alpha_t = 1 - \beta_t$                | æ¯ä¸€æ­¥ä¿ç•™åŸå›¾çš„æ¯”ä¾‹                    |
| $\bar{\alpha}t = \prod{s=1}^t \alpha_s$ | åˆ°ç¬¬ t æ­¥ä¸ºæ­¢ç´¯è®¡ä¿ç•™åŸå›¾çš„æ¯”ä¾‹         |



## **âœ… è®­ç»ƒæ–¹å¼ä¸€ï¼š** **é¢„æµ‹å™ªå£°** $\epsilon$**ï¼ˆæœ€ä¸»æµåšæ³•ï¼‰**

æœ€å¸¸è§çš„ diffusionï¼ˆæ¯”å¦‚ DDPMï¼‰æ˜¯ç”¨ **å™ªå£°é¢„æµ‹** çš„æ–¹å¼æ¥è®­ç»ƒç½‘ç»œã€‚

### **ğŸ§ª æ•°æ®æ„é€ ï¼ˆé‡‡æ ·è®­ç»ƒæ ·æœ¬ï¼‰**

å¯¹äºæ¯ä¸€å¼ å›¾åƒ $x_0 \sim \text{çœŸå®å›¾åƒ}$ï¼Œæˆ‘ä»¬åšä»¥ä¸‹æ­¥éª¤ï¼š

1. éšæœºé‡‡æ ·ä¸€ä¸ªæ—¶é—´æ­¥ $t \sim \{1, \dots, T\}$
2. é‡‡ä¸€ä¸ªéšæœºå™ªå£° $\epsilon \sim \mathcal{N}(0, I)$
3. æŒ‰ç…§ closed-form çš„åŠ å™ªå…¬å¼å¾—åˆ° $x_t$ï¼š

$x_t = \sqrt{\bar{\alpha}_t} x_0 + \sqrt{1 - \bar{\alpha}_t} \epsilon$

å…¶ä¸­ $\bar{\alpha}t = \prod{s=1}^{t}(1 - \beta_s)$ æ˜¯ç´¯è®¡çš„ä¿æŒæ¯”ä¾‹ã€‚

- $x_0$ï¼šåŸå§‹å›¾åƒï¼›
- $\epsilon \sim \mathcal{N}(0, I)$ï¼šæ ‡å‡†é«˜æ–¯å™ªå£°ï¼›
- $\sqrt{\bar{\alpha}_t}$ï¼šå½“å‰ä¿ç•™å›¾åƒä¿¡æ¯çš„æ¯”ä¾‹ï¼›
- $\sqrt{1 - \bar{\alpha}_t}$ï¼šå½“å‰æ··å…¥å™ªå£°çš„æ¯”ä¾‹ã€‚

è¿™è¡¨ç¤ºï¼š**åœ¨ä»»æ„æ—¶é—´æ­¥** t**ï¼Œæˆ‘ä»¬éƒ½èƒ½ç›´æ¥é‡‡æ ·å¯¹åº”çš„ noisy å›¾åƒ** $x_t$ã€‚

### **ğŸ¯ ç¥ç»ç½‘ç»œç›®æ ‡ï¼šé¢„æµ‹å™ªå£°**

æˆ‘ä»¬è®­ç»ƒä¸€ä¸ªç¥ç»ç½‘ç»œ $\epsilon_\theta(x_t, t)$ï¼Œç›®æ ‡æ˜¯é¢„æµ‹æˆ‘ä»¬åŠ è¿›å»çš„å™ªå£° $\epsilon$ã€‚è®­ç»ƒç›®æ ‡æ˜¯ï¼š

$L(\theta) = \mathbb{E}{x_0, \epsilon, t} \left[ \left\| \epsilon\theta(x_t, t) - \epsilon \right\|^2 \right]$

è¿™æ ·ç½‘ç»œå­¦ä¼šäº†ï¼šç»™å®šä¸€ä¸ª noisy å›¾åƒå’Œæ—¶é—´æ­¥ï¼Œå®ƒèƒ½å‘Šè¯‰ä½ è¿™ä¸ªå›¾åƒé‡Œè—äº†å¤šå°‘å™ªå£°ã€‚

- $\theta$ï¼šç½‘ç»œçš„å¯å­¦ä¹ å‚æ•°ï¼›

- $x_0$ï¼šä»æ•°æ®é›†ä¸­é‡‡æ ·çš„ä¸€å¼ çœŸå®å›¾åƒï¼›
- $\epsilon \sim \mathcal{N}(0, I)$ï¼šæˆ‘ä»¬äººä¸ºåŠ è¿›å»çš„éšæœºå™ªå£°ï¼›
- $t \sim \text{Uniform}(1, T)$ï¼šéšæœºé€‰å–ä¸€ä¸ªæ—¶é—´æ­¥ï¼›
- $x_t$ï¼šç”±å‰å‘è¿‡ç¨‹å…¬å¼è®¡ç®—å‡ºæ¥çš„ noisy å›¾åƒï¼›
- $\epsilon_\theta(x_t, t)$ï¼šæ¨¡å‹çš„é¢„æµ‹è¾“å‡ºï¼Œä¸€ä¸ªä¸ $x_t$ åŒå½¢çŠ¶çš„å¼ é‡ï¼›
- ç›®æ ‡ï¼š**è®©æ¨¡å‹é¢„æµ‹å‡ºçš„å™ªå£°å°½é‡æ¥è¿‘æˆ‘ä»¬çœŸå®åŠ è¿›å»çš„å™ªå£°** $\epsilon$ã€‚



## **ğŸ¤– ç½‘ç»œç»“æ„æ€ä¹ˆè®¾è®¡ï¼Ÿ**

### **1.** **è¾“å…¥æ˜¯ä¸¤ä¸ªä¸œè¥¿**

- $x_t$ï¼šä¸€å¼  noisy å›¾åƒï¼Œå½¢çŠ¶å’ŒåŸå§‹å›¾åƒä¸€æ ·ï¼ˆæ¯”å¦‚ $3 \times 64 \times 64$ï¼‰
- tï¼šä¸€ä¸ªæ•´æ•°æ—¶é—´æ­¥ï¼Œè¡¨ç¤ºå½“å‰å›¾åƒä¸­æ··å…¥äº†å¤šå°‘å™ªå£°

### **2.** **ç½‘ç»œç»“æ„ä¸€èˆ¬æ˜¯ U-Net**ï¼ˆç‰¹åˆ«é€‚åˆå›¾åƒå¤„ç†ï¼‰

- è¾“å…¥ï¼šnoisy å›¾åƒ $x_t$
- æ—¶é—´æ­¥ t ä¼šè¢«ç¼–ç æˆä¸€ä¸ªæ—¶é—´å‘é‡ï¼ˆembeddingï¼‰ï¼ŒåŠ å…¥åˆ°æ¯ä¸€å±‚
- ä½¿ç”¨ skip-connectionï¼Œä¿ç•™é«˜åˆ†è¾¨ç‡ä¿¡æ¯
- è¾“å‡ºå’Œè¾“å…¥åŒæ ·å¤§å°ï¼Œè¡¨ç¤ºæ¯ä¸ªåƒç´ çš„å™ªå£°å€¼ï¼ˆå’Œ $\epsilon$ åŒå‹ï¼‰

è¿™å°±æ˜¯ diffusion æ¨¡å‹çš„æ ¸å¿ƒç½‘ç»œã€‚

### **3.** **æ—¶é—´æ­¥** t **çš„å¤„ç†æ–¹å¼**

æ—¶é—´æ˜¯ä¸€ä¸ªæ•´æ•° $t \in \{1, \dots, T\}$ï¼Œä¸èƒ½ç›´æ¥é€ç»™ç½‘ç»œã€‚ä¸€èˆ¬çš„åšæ³•æ˜¯ï¼š

- ç”¨ä¸€ä¸ª **ä½ç½®ç¼–ç ï¼ˆPositional Encodingï¼‰** æŠŠ t ç¼–æˆä¸€ä¸ªå‘é‡ï¼›
- åŠ å…¥åˆ°ç½‘ç»œçš„æ¯ä¸€å±‚ï¼ˆæ¯”å¦‚ç”¨ FiLM æˆ–ç›´æ¥åŠ åˆ°æ¿€æ´»ä¸Šï¼‰ï¼›

è¿™æ ·ç½‘ç»œå°±çŸ¥é“å½“å‰æ˜¯å“ªä¸€æ­¥ï¼Œè¿˜åŸå¤šå°‘ç»“æ„ã€‚

### **è¾“å‡ºï¼š**

- ä¸€ä¸ªå’Œ $x_t$ åŒæ ·å½¢çŠ¶çš„å¼ é‡ï¼›
- è¡¨ç¤ºæ¯ä¸ªåƒç´ çš„å™ªå£°é¢„æµ‹å€¼ï¼›



## **âœ… æ¨ç†é˜¶æ®µæ€ä¹ˆç”¨è¿™ä¸ªç½‘ç»œï¼Ÿ**

è®­ç»ƒå®Œç½‘ç»œåï¼Œæˆ‘ä»¬å¯ä»¥ç”¨å®ƒä¸€æ­¥æ­¥å»å™ªï¼š

1. ä» $x_T \sim \mathcal{N}(0, I)$é‡‡æ ·
2. ç”¨ç¥ç»ç½‘ç»œé¢„æµ‹å™ªå£° $\hat{\epsilon}_\theta(x_T, T)$
3. ç”¨ä¸‹é¢çš„å…¬å¼è¿˜åŸ $x_{T-1}$ï¼š

$x_{t-1} = \frac{1}{\sqrt{1 - \beta_t}} \left( x_t - \beta_t \cdot \hat{\epsilon}_\theta(x_t, t) / \sqrt{1 - \bar{\alpha}_t} \right) + \text{some noise}$

é‡å¤ä¸Šé¢çš„æ­¥éª¤ç›´åˆ° x_0ï¼Œå¾—åˆ°ä¸€å¼ æ–°å›¾åƒã€‚



## **ğŸ” æ€»ç»“ä¸€ä¸‹ï¼š**

| **æ­¥éª¤** | **å†…å®¹**                                       |
| -------- | ---------------------------------------------- |
| è®­ç»ƒç›®æ ‡ | è®©ç¥ç»ç½‘ç»œé¢„æµ‹å›¾åƒé‡Œçš„å™ªå£°                     |
| ç½‘ç»œç»“æ„ | U-Net + æ—¶é—´æ­¥ç¼–ç                              |
| è¾“å…¥è¾“å‡º | è¾“å…¥ noisy å›¾åƒ $x_t$ å’Œæ—¶é—´æ­¥ tï¼Œè¾“å‡ºé¢„æµ‹å™ªå£° |
| æŸå¤±å‡½æ•° | MSEï¼šé¢„æµ‹çš„å™ªå£° vs å®é™…åŠ è¿›å»çš„å™ªå£°            |
| æ¨ç†è¿‡ç¨‹ | ä»å™ªå£°å‡ºå‘ï¼Œé€æ­¥å»å™ªæ¢å¤å›¾åƒ                   |





# ä»£ç ç»ƒä¹ 



æˆ‘ä»¬å°±é€šè¿‡ä¸€ä¸ª**ä»å¤´è®­ç»ƒ diffusion æ¨¡å‹çš„å®Œæ•´ PyTorch demo**ï¼Œä¸€æ­¥ä¸€æ­¥èµ°ä¸€éæµç¨‹ã€‚

ä¸ºäº†ç®€å•æ¸…æ™°ï¼Œæˆ‘ä»¬ä½¿ç”¨ **MNISTï¼ˆ28x28 ç°åº¦å›¾åƒï¼‰** ä½œä¸ºè®­ç»ƒæ•°æ®ï¼Œä½¿ç”¨ç»å…¸çš„ **DDPMï¼ˆdenoising diffusion probabilistic modelï¼‰** æ¡†æ¶ã€‚

------



## **ğŸ§© æ•´ä½“ç»“æ„åˆ†ä¸º 4 æ­¥ï¼š**

1. åŠ å™ªå‡½æ•°ï¼ˆå‰å‘è¿‡ç¨‹ï¼‰
2. ç½‘ç»œç»“æ„ï¼ˆä¸€ä¸ªå° U-Netï¼‰
3. æŸå¤±å‡½æ•°ï¼ˆå™ªå£°é¢„æµ‹ï¼‰
4. è®­ç»ƒå¾ªç¯



## **ğŸ§ª Step 0: å®‰è£…ä¾èµ–ï¼ˆåªéœ€ PyTorch å’Œ torchvisionï¼‰**

```
pip install torch torchvision
```

## **ğŸ§  Step 1: å‰å‘åŠ å™ªå‡½æ•°**

```python
import torch
import torch.nn.functional as F
import numpy as np

# beta scheduleï¼ˆå™ªå£°å¼ºåº¦ï¼‰çº¿æ€§ä»å°åˆ°å¤§
T = 300  # æ—¶é—´æ­¥æ•°
beta = torch.linspace(1e-4, 0.02, T)
alpha = 1.0 - beta
alpha_bar = torch.cumprod(alpha, dim=0)

# åŠ å™ªå‡½æ•° q(x_t | x_0)
def q_sample(x_0, t, noise=None):
    if noise is None:
        noise = torch.randn_like(x_0)
    sqrt_alpha_bar_t = torch.sqrt(alpha_bar[t]).view(-1, 1, 1, 1)
    sqrt_one_minus_alpha_bar_t = torch.sqrt(1 - alpha_bar[t]).view(-1, 1, 1, 1)
    return sqrt_alpha_bar_t * x_0 + sqrt_one_minus_alpha_bar_t * noise
```

## **ğŸ§± Step 2: ä¸€ä¸ªç®€å•çš„ U-Net ç½‘ç»œç»“æ„ï¼ˆé€‚é… MNISTï¼‰**

```python
import torch.nn as nn

class SimpleUNet(nn.Module):
    def __init__(self):
        super().__init__()
        self.net = nn.Sequential(
            nn.Conv2d(1 + 1, 32, 3, padding=1),  # å›¾åƒ + æ—¶é—´é€šé“
            nn.ReLU(),
            nn.Conv2d(32, 64, 3, padding=1),
            nn.ReLU(),
            nn.Conv2d(64, 32, 3, padding=1),
            nn.ReLU(),
            nn.Conv2d(32, 1, 3, padding=1),  # è¾“å‡ºä¸è¾“å…¥åŒå½¢çŠ¶
        )

    def forward(self, x, t):
        # æŠŠæ—¶é—´æ­¥ t ç¼–ç æˆä¸€å¼ å’Œå›¾åƒä¸€æ ·å¤§å°çš„é€šé“å›¾
        t = t.float() / T
        t = t.view(-1, 1, 1, 1).expand(x.shape[0], 1, 28, 28)
        x = torch.cat([x, t], dim=1)  # æ‹¼æ¥æ—¶é—´é€šé“
        return self.net(x)
```

## **ğŸ¯ Step 3: è®­ç»ƒ loss å‡½æ•°ï¼ˆé¢„æµ‹å™ªå£°ï¼‰**

```python
def diffusion_loss(model, x_0, t):
    noise = torch.randn_like(x_0)
    x_t = q_sample(x_0, t, noise)
    pred_noise = model(x_t, t)
    return F.mse_loss(pred_noise, noise)
```

## **ğŸ” Step 4: è®­ç»ƒå¾ªç¯**

```python
from torchvision import datasets, transforms
from torch.utils.data import DataLoader

device = 'cuda' if torch.cuda.is_available() else 'cpu'

# åŠ è½½ MNIST æ•°æ®
transform = transforms.Compose([
    transforms.ToTensor(),
    lambda x: x * 2. - 1.  # å½’ä¸€åŒ–åˆ° [-1, 1]
])
dataset = datasets.MNIST(root='./data', train=True, transform=transform, download=True)
dataloader = DataLoader(dataset, batch_size=128, shuffle=True)

# åˆå§‹åŒ–æ¨¡å‹
model = SimpleUNet().to(device)
optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)

# è®­ç»ƒä¸»å¾ªç¯
for epoch in range(10):
    for x, _ in dataloader:
        x = x.to(device)
        t = torch.randint(0, T, (x.shape[0],), device=device).long()
        loss = diffusion_loss(model, x, t)

        optimizer.zero_grad()
        loss.backward()
        optimizer.step()

    print(f"Epoch {epoch}: loss = {loss.item():.4f}")
```



------



## **ğŸ¨ (Bonus) æ¨ç†é‡‡æ ·å‡½æ•°ï¼ˆç”Ÿæˆå›¾åƒï¼‰**

```python
@torch.no_grad()
def sample(model, n_samples=16):
    model.eval()
    x = torch.randn(n_samples, 1, 28, 28).to(device)

    for t_ in reversed(range(T)):
        t = torch.full((n_samples,), t_, device=device, dtype=torch.long)
        noise_pred = model(x, t)

        beta_t = beta[t].view(-1, 1, 1, 1).to(device)
        alpha_t = alpha[t].view(-1, 1, 1, 1).to(device)
        alpha_bar_t = alpha_bar[t].view(-1, 1, 1, 1).to(device)

        if t_ > 0:
            noise = torch.randn_like(x)
        else:
            noise = torch.zeros_like(x)

        x = 1 / torch.sqrt(alpha_t) * (x - (1 - alpha_t) / torch.sqrt(1 - alpha_bar_t) * noise_pred) + torch.sqrt(beta_t) * noise

    return x
```



------



## **âœ… è¿è¡Œ sample åä½ å¯ä»¥ç”¨ matplotlib å±•ç¤ºç”Ÿæˆå›¾åƒï¼š**

```python
import matplotlib.pyplot as plt

samples = sample(model, 16).cpu()
grid = samples.view(4, 4, 28, 28).permute(0, 2, 1, 3).reshape(4*28, 4*28)
plt.imshow(grid, cmap='gray')
plt.axis('off')
plt.show()
```



## **ğŸ“Œ æ€»ç»“**

ä½ ç°åœ¨æœ‰äº†ä¸€ä¸ªå®Œæ•´çš„ diffusion æ¨¡å‹è®­ç»ƒç®¡çº¿ï¼š

1. ä»çœŸå®å›¾åƒæ„é€  noisy å›¾åƒï¼›
2. ç”¨ç¥ç»ç½‘ç»œé¢„æµ‹å™ªå£°ï¼›
3. ç”¨ MSE loss è®­ç»ƒç½‘ç»œï¼›
4. ç”¨ç½‘ç»œé€æ­¥è¿˜åŸå›¾åƒã€‚





